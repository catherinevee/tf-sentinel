# Policy: AWS Comprehensive Compliance and Governance Framework
# Purpose: Enforces organizational compliance requirements with fail-secure defaults and comprehensive validation
# Scope: All AWS resources with compliance requirements (SOC2, HIPAA, PCI-DSS, GDPR, SOX)
# Enforcement: hard-mandatory
#
# Validates:
# - Mandatory resource tagging for governance and cost allocation
# - Data retention and backup policies
# - Logging and monitoring requirements
# - Audit trail configurations
# - Data residency and sovereignty requirements
# - Change management and approval workflows
# - Service control policies compliance
# - Industry-specific compliance controls

import "tfplan/v2" as tfplan
import "tfstate/v2" as tfstate  
import "tfconfig/v2" as tfconfig
import "tfrun" as tfrun
import "strings"

# Parameters with secure compliance defaults
param environment default "dev"
param compliance_frameworks default ["soc2", "iso27001"]
param data_classification_required default true
param audit_logging_required default true
param backup_retention_days_min default 7
param log_retention_days_min default 90
param require_change_approval default true

# Compliance framework requirements
compliance_requirements = {
    "soc2": {
        "encryption_required": true,
        "logging_required": true,
        "backup_required": true,
        "access_controls": true,
        "monitoring_required": true
    },
    "hipaa": {
        "encryption_required": true,
        "logging_required": true,
        "backup_required": true,
        "access_controls": true,
        "data_residency": true,
        "audit_trail": true
    },
    "pci_dss": {
        "encryption_required": true,
        "network_segmentation": true,
        "access_controls": true,
        "logging_required": true,
        "vulnerability_management": true
    },
    "gdpr": {
        "data_residency": true,
        "encryption_required": true,
        "data_retention_policies": true,
        "access_controls": true,
        "audit_trail": true
    },
    "sox": {
        "change_management": true,
        "segregation_of_duties": true,
        "audit_trail": true,
        "backup_required": true,
        "monitoring_required": true
    }
}

# Comprehensive compliance validation with defense in depth
validate_compliance = func(resource) {
    # Input validation - fail secure on null/undefined
    if resource is null {
        print("COMPLIANCE ERROR: Resource validation failed - null resource detected")
        return false
    }
    
    if resource.change is null {
        print("COMPLIANCE ERROR: Resource change is null for:", resource.address else "unknown")
        return false
    }
    
    violations = []
    resource_type = resource.type else "unknown"
    resource_address = resource.address else "unknown"
    
    # Check for computed values - handle gracefully but securely
    if resource.change.after is computed {
        print("WARNING: Resource attributes are computed for", resource_address, "- applying conservative compliance validation")
        return validate_compliance_with_computed_values(resource)
    }
    
    # Mandatory Tagging Compliance
    violations = append(violations, validate_compliance_tagging(resource)...)
    
    # Data Protection and Retention Compliance
    violations = append(violations, validate_data_protection_compliance(resource)...)
    
    # Logging and Monitoring Compliance
    violations = append(violations, validate_logging_compliance(resource)...)
    
    # Backup and Recovery Compliance
    violations = append(violations, validate_backup_compliance(resource)...)
    
    # Access Control Compliance
    violations = append(violations, validate_access_control_compliance(resource)...)
    
    # Data Residency Compliance
    violations = append(violations, validate_data_residency_compliance(resource)...)
    
    # Change Management Compliance
    violations = append(violations, validate_change_management_compliance(resource)...)
    
    # Framework-Specific Compliance
    for compliance_frameworks as framework {
        violations = append(violations, validate_framework_compliance(resource, framework)...)
    }
    
    # Report violations with detailed context
    if length(violations) > 0 {
        print("COMPLIANCE POLICY VIOLATIONS found for", resource_address + ":")
        for violations as violation {
            print("  - VIOLATION:", violation)
        }
        return false
    }
    
    return true
}

# Compliance Tagging Validation
validate_compliance_tagging = func(resource) {
    violations = []
    resource_after = resource.change.after else {}
    
    # Required compliance tags
    mandatory_compliance_tags = [
        "Environment",
        "Owner", 
        "CostCenter",
        "Project",
        "DataClassification",
        "ComplianceFramework",
        "BackupRequired",
        "RetentionPeriod"
    ]
    
    tags = resource_after.tags else {}
    
    for mandatory_compliance_tags as tag {
        if tag not in keys(tags) {
            append(violations, "Missing mandatory compliance tag: " + tag)
        } else {
            tag_value = tags[tag] else ""
            if length(tag_value) == 0 {
                append(violations, "Empty value for compliance tag: " + tag)
            }
            
            # Validate specific tag formats
            violations = append(violations, validate_tag_format(tag, tag_value)...)
        }
    }
    
    # Validate data classification
    if data_classification_required {
        data_classification = tags["DataClassification"] else ""
        valid_classifications = ["public", "internal", "confidential", "restricted"]
        if data_classification not in valid_classifications {
            append(violations, "Invalid DataClassification tag value: " + data_classification)
        }
    }
    
    return violations
}

# Tag Format Validation
validate_tag_format = func(tag_name, tag_value) {
    violations = []
    
    # CostCenter format validation
    if tag_name is "CostCenter" {
        if not strings.matches(tag_value, "^[A-Z]{2,4}-[0-9]{4,6}$") {
            append(violations, "CostCenter tag must follow format: DEPT-1234")
        }
    }
    
    # Owner email validation
    if tag_name is "Owner" {
        if not strings.contains(tag_value, "@") {
            append(violations, "Owner tag should be a valid email address")
        }
    }
    
    # Environment validation
    if tag_name is "Environment" {
        valid_environments = ["dev", "test", "staging", "prod", "sandbox"]
        if tag_value not in valid_environments {
            append(violations, "Environment tag must be one of: " + strings.join(valid_environments, ", "))
        }
    }
    
    return violations
}

# Data Protection Compliance Validation
validate_data_protection_compliance = func(resource) {
    violations = []
    resource_after = resource.change.after else {}
    resource_type = resource.type
    
    # Encryption validation for data stores
    data_store_types = [
        "aws_s3_bucket",
        "aws_db_instance",
        "aws_rds_cluster", 
        "aws_dynamodb_table",
        "aws_ebs_volume",
        "aws_efs_file_system"
    ]
    
    if resource_type in data_store_types {
        violations = append(violations, validate_encryption_compliance(resource)...)
    }
    
    # Data classification enforcement
    tags = resource_after.tags else {}
    data_classification = tags["DataClassification"] else ""
    
    if data_classification in ["confidential", "restricted"] {
        # Enhanced requirements for sensitive data
        violations = append(violations, validate_sensitive_data_requirements(resource)...)
    }
    
    return violations
}

# Encryption Compliance Validation
validate_encryption_compliance = func(resource) {
    violations = []
    resource_after = resource.change.after else {}
    resource_type = resource.type
    
    # S3 encryption compliance
    if resource_type is "aws_s3_bucket" {
        sse_config = resource_after.server_side_encryption_configuration else []
        if length(sse_config) == 0 {
            append(violations, "S3 bucket must have server-side encryption for compliance")
        }
    }
    
    # RDS encryption compliance
    if resource_type in ["aws_db_instance", "aws_rds_cluster"] {
        storage_encrypted = resource_after.storage_encrypted else false
        if not storage_encrypted {
            append(violations, "RDS instance must be encrypted for compliance")
        }
    }
    
    # DynamoDB encryption compliance
    if resource_type is "aws_dynamodb_table" {
        server_side_encryption = resource_after.server_side_encryption else []
        if length(server_side_encryption) == 0 {
            append(violations, "DynamoDB table must have server-side encryption for compliance")
        }
    }
    
    return violations
}

# Sensitive Data Requirements Validation
validate_sensitive_data_requirements = func(resource) {
    violations = []
    resource_after = resource.change.after else {}
    
    # Additional requirements for sensitive data
    if resource.type is "aws_s3_bucket" {
        # Check for versioning
        versioning = resource_after.versioning else []
        if length(versioning) == 0 {
            append(violations, "S3 bucket with sensitive data must have versioning enabled")
        }
        
        # Check for MFA delete protection
        # Note: MFA delete is typically configured outside Terraform
        append(violations, "Ensure MFA delete is enabled for sensitive data buckets")
    }
    
    return violations
}

# Logging Compliance Validation
validate_logging_compliance = func(resource) {
    violations = []
    resource_after = resource.change.after else {}
    resource_type = resource.type
    
    if not audit_logging_required {
        return violations
    }
    
    # VPC Flow Logs compliance
    if resource_type is "aws_vpc" {
        # Note: VPC Flow Logs are typically configured separately
        append(violations, "Ensure VPC Flow Logs are enabled for compliance")
    }
    
    # S3 access logging compliance
    if resource_type is "aws_s3_bucket" {
        logging = resource_after.logging else []
        if length(logging) == 0 {
            append(violations, "S3 bucket must have access logging enabled for compliance")
        }
    }
    
    # RDS logging compliance
    if resource_type is "aws_db_instance" {
        enabled_cloudwatch_logs_exports = resource_after.enabled_cloudwatch_logs_exports else []
        if length(enabled_cloudwatch_logs_exports) == 0 {
            append(violations, "RDS instance should export logs to CloudWatch for compliance")
        }
    }
    
    return violations
}

# Backup Compliance Validation
validate_backup_compliance = func(resource) {
    violations = []
    resource_after = resource.change.after else {}
    resource_type = resource.type
    
    # RDS backup compliance
    if resource_type is "aws_db_instance" {
        backup_retention_period = resource_after.backup_retention_period else 0
        if backup_retention_period < backup_retention_days_min {
            append(violations, "RDS backup retention must be at least " + string(backup_retention_days_min) + " days for compliance")
        }
        
        # Check backup window configuration
        backup_window = resource_after.backup_window else ""
        if length(backup_window) == 0 {
            append(violations, "RDS instance must have backup window configured for compliance")
        }
    }
    
    # DynamoDB backup compliance
    if resource_type is "aws_dynamodb_table" {
        point_in_time_recovery = resource_after.point_in_time_recovery else []
        if length(point_in_time_recovery) == 0 {
            append(violations, "DynamoDB table must have point-in-time recovery enabled for compliance")
        }
    }
    
    # EBS snapshot compliance
    if resource_type is "aws_ebs_volume" {
        tags = resource_after.tags else {}
        backup_required = tags["BackupRequired"] else "false"
        if backup_required is "true" {
            append(violations, "Ensure automated EBS snapshots are configured for this volume")
        }
    }
    
    return violations
}

# Access Control Compliance Validation
validate_access_control_compliance = func(resource) {
    violations = []
    resource_after = resource.change.after else {}
    resource_type = resource.type
    
    # S3 public access compliance
    if resource_type is "aws_s3_bucket" {
        acl = resource_after.acl else ""
        if acl in ["public-read", "public-read-write"] {
            append(violations, "S3 bucket cannot have public ACL for compliance")
        }
    }
    
    # Security Group compliance
    if resource_type is "aws_security_group" {
        ingress_rules = resource_after.ingress else []
        for ingress_rules as rule {
            cidr_blocks = rule.cidr_blocks else []
            if "0.0.0.0/0" in cidr_blocks {
                from_port = rule.from_port else 0
                if from_port not in [80, 443] {
                    append(violations, "Security group rule violates least privilege principle for compliance")
                }
            }
        }
    }
    
    return violations
}

# Data Residency Compliance Validation
validate_data_residency_compliance = func(resource) {
    violations = []
    
    # Check if data residency is required by any compliance framework
    requires_data_residency = false
    for compliance_frameworks as framework {
        framework_reqs = compliance_requirements[framework] else {}
        if framework_reqs["data_residency"] else false {
            requires_data_residency = true
        }
    }
    
    if requires_data_residency {
        # Note: Data residency is typically enforced through provider configuration
        # This is more of an informational check
        append(violations, "Ensure resource deployment complies with data residency requirements")
    }
    
    return violations
}

# Change Management Compliance Validation
validate_change_management_compliance = func(resource) {
    violations = []
    
    if require_change_approval and environment is "prod" {
        # Check for proper change management tags
        resource_after = resource.change.after else {}
        tags = resource_after.tags else {}
        
        change_id = tags["ChangeId"] else ""
        approver = tags["Approver"] else ""
        
        if length(change_id) == 0 {
            append(violations, "Production changes must include ChangeId tag for compliance")
        }
        
        if length(approver) == 0 {
            append(violations, "Production changes must include Approver tag for compliance")
        }
    }
    
    return violations
}

# Framework-Specific Compliance Validation
validate_framework_compliance = func(resource, framework) {
    violations = []
    
    framework_reqs = compliance_requirements[framework] else {}
    
    # SOX-specific validations
    if framework is "sox" {
        violations = append(violations, validate_sox_compliance(resource)...)
    }
    
    # HIPAA-specific validations
    if framework is "hipaa" {
        violations = append(violations, validate_hipaa_compliance(resource)...)
    }
    
    # PCI-DSS-specific validations
    if framework is "pci_dss" {
        violations = append(violations, validate_pci_compliance(resource)...)
    }
    
    return violations
}

# SOX Compliance Validation
validate_sox_compliance = func(resource) {
    violations = []
    
    # SOX requires strong change controls and audit trails
    if environment is "prod" {
        resource_after = resource.change.after else {}
        tags = resource_after.tags else {}
        
        # Check for segregation of duties
        created_by = tags["CreatedBy"] else ""
        approved_by = tags["ApprovedBy"] else ""
        
        if created_by is approved_by and length(created_by) > 0 {
            append(violations, "SOX compliance requires segregation of duties - creator and approver must be different")
        }
    }
    
    return violations
}

# HIPAA Compliance Validation
validate_hipaa_compliance = func(resource) {
    violations = []
    
    # HIPAA requires additional safeguards for PHI
    resource_after = resource.change.after else {}
    tags = resource_after.tags else {}
    data_classification = tags["DataClassification"] else ""
    
    if data_classification in ["confidential", "restricted"] {
        # Check for audit logging
        if resource.type is "aws_s3_bucket" {
            append(violations, "HIPAA compliance requires comprehensive audit logging for PHI storage")
        }
    }
    
    return violations
}

# PCI-DSS Compliance Validation
validate_pci_compliance = func(resource) {
    violations = []
    
    # PCI-DSS requires network segmentation and strong access controls
    if resource.type is "aws_security_group" {
        resource_after = resource.change.after else {}
        tags = resource_after.tags else {}
        
        if tags["PCIScope"] else "false" is "true" {
            append(violations, "PCI-scoped security groups require additional review and validation")
        }
    }
    
    return violations
}

# Handle computed values securely
validate_compliance_with_computed_values = func(resource) {
    print("INFO: Applying conservative compliance validation for computed resource:", resource.address else "unknown")
    
    # For computed resources, apply default compliance assumptions
    resource_type = resource.type else "unknown"
    
    # Allow common resource types with computed values but flag for review
    print("COMPLIANCE INFO: Computed resource requires manual compliance verification:", resource_type)
    return true
}

# Efficient resource filtering for compliance
compliance_controlled_resources = filter tfplan.resource_changes as _, rc {
    rc.mode is "managed" and
    rc.change.actions is not ["delete"]
}

# Main rule with comprehensive compliance validation
main = rule when length(compliance_controlled_resources) > 0 {
    all compliance_controlled_resources as _, resource {
        validate_compliance(resource)
    }
}
